{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      41. Kadang aku berfikir kenapa aku tetap perca...\n",
      "1      USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...\n",
      "2      USER USER Kaum cebong kapir udah keliatan dong...\n",
      "3      USER Ya bani taplak dkk \\xf0\\x9f\\x98\\x84\\xf0\\x...\n",
      "4      deklarasi pilkada 2018 aman dan anti hoax warg...\n",
      "                             ...                        \n",
      "292    RT USER USER USER USER USER USER USER Haha kal...\n",
      "293    #GubernurZamanNow #GusIpulPuti2 #GanjarYasin1 ...\n",
      "294    RT USER: USER Yg cinta orba pasti meng idola k...\n",
      "295    Nantang buka Dadalah, eh nyebut Setanlah emang...\n",
      "296    USER USER USER USER \"BELAH\" duren yaaaa.\\nGak ...\n",
      "Name: Tweet, Length: 297, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"unprocessed tweet.csv\", encoding='latin-1')\n",
    "first_column_pre_process = data.iloc[:, 0]\n",
    "\n",
    "print(first_column_pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41. kadang aku berfikir kenapa aku tetap perca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user user aku itu aku\\n\\nku tau matamu sipit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user user kaum cebong kapir udah keliatan dong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user ya bani taplak dkk \\xf0\\x9f\\x98\\x84\\xf0\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deklarasi pilkada 2018 aman dan anti hoax warg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>rt user user user user user user user haha kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>#gubernurzamannow #gusipulputi2 #ganjaryasin1 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>rt user: user yg cinta orba pasti meng idola k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>nantang buka dadalah, eh nyebut setanlah emang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>user user user user \"belah\" duren yaaaa.\\ngak ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Processed Text\n",
       "0    41. kadang aku berfikir kenapa aku tetap perca...\n",
       "1    user user aku itu aku\\n\\nku tau matamu sipit t...\n",
       "2    user user kaum cebong kapir udah keliatan dong...\n",
       "3    user ya bani taplak dkk \\xf0\\x9f\\x98\\x84\\xf0\\x...\n",
       "4    deklarasi pilkada 2018 aman dan anti hoax warg...\n",
       "..                                                 ...\n",
       "292  rt user user user user user user user haha kal...\n",
       "293  #gubernurzamannow #gusipulputi2 #ganjaryasin1 ...\n",
       "294  rt user: user yg cinta orba pasti meng idola k...\n",
       "295  nantang buka dadalah, eh nyebut setanlah emang...\n",
       "296  user user user user \"belah\" duren yaaaa.\\ngak ...\n",
       "\n",
       "[297 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lowercase(text):\n",
    "    new_text = text.lower()\n",
    "    return new_text\n",
    "\n",
    "cleaned_tweet = []\n",
    "for text in first_column_pre_process:\n",
    "    cleaned_tweet.append(lowercase(text))\n",
    "\n",
    "    \n",
    "cleaned_tweet = pd.DataFrame(cleaned_tweet, columns = ['Processed Text'])   \n",
    "\n",
    "cleaned_tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned Tweet\n",
      "0     kadang aku berfikir kenapa aku tetap percaya ...\n",
      "1     aku itu aku ku tau matamu sipit tapi diliat d...\n",
      "2     kaum cebong kapir udah keliatan dongoknya dar...\n",
      "3                     ya bani taplak dkk \\\\\\\\\\\\\\\\\\\\\\\\'\n",
      "4    deklarasi pilkada 2018 aman dan anti hoax warg...\n",
      "..                                                 ...\n",
      "292            haha kalah ni yee org jahat pasti kalah\n",
      "293  #gubernurzamannow #gusipulputi2 #ganjaryasin1 ...\n",
      "294   : yg cinta orba pasti meng idola kan prabowo ...\n",
      "295  nantang buka dadalah, eh nyebut setanlah emang...\n",
      "296   \"belah\" duren yaaaa. gak dungu,ya gak cebong....\n",
      "\n",
      "[297 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub(r'\\\\n',' ', text)\n",
    "    text = re.sub('rt','', text)\n",
    "    text = re.sub('user','', text)\n",
    "    text = re.sub(';','', text)\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text)\n",
    "    text = re.sub('  +',' ', text)\n",
    "    text = re.sub('\\d+\\.\\s',' ', text)\n",
    "    text = re.sub(r\"x[a-z0-9][a-z0-9]\",'',text)\n",
    "        \n",
    "    return text\n",
    "\n",
    "\n",
    "cleaned_tweet = []\n",
    "for text in first_column_pre_process:\n",
    "    text = lowercase(text)\n",
    "    cleaned_tweet.append(remove_unnecessary_char(text))\n",
    "\n",
    "    \n",
    "cleaned_tweet = pd.DataFrame(cleaned_tweet, columns = ['Cleaned Tweet'])   \n",
    "\n",
    "print(cleaned_tweet)\n",
    "cleaned_tweet.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned Tweet\n",
      "0    kadang aku berfikir kenapa aku tetap percaya p...\n",
      "1    aku itu aku ku tau matamu sipit tapi diliat da...\n",
      "2    kaum cebong kapir udah keliatan dongoknya dari...\n",
      "3                                  ya bani taplak dkk \n",
      "4    deklarasi pilkada 2018 aman dan anti hoax warg...\n",
      "..                                                 ...\n",
      "292            haha kalah ni yee org jahat pasti kalah\n",
      "293  gubernurzamannow gusipulputi2 ganjaryasin1 dja...\n",
      "294  yg cinta orba pasti meng idola kan prabowo amp...\n",
      "295  nantang buka dadalah eh nyebut setanlah emang ...\n",
      "296  belah duren yaaaa gak dungu ya gak cebong maaf...\n",
      "\n",
      "[297 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub(r'[^0-9a-zA-Z\\?!]+', ' ', text)\n",
    "    text = re.sub(\"\\s\\s+\" , \" \", text)\n",
    "    text = re.sub('^\\s','', text)\n",
    "    return text\n",
    "\n",
    "cleaned_tweet = []\n",
    "for text in first_column_pre_process:\n",
    "    text = lowercase(text)\n",
    "    text = remove_unnecessary_char(text)\n",
    "    text = remove_nonaplhanumeric(text)\n",
    "    cleaned_tweet.append(text)\n",
    "\n",
    "cleaned_tweet = pd.DataFrame(cleaned_tweet, columns = ['Cleaned Tweet'])   \n",
    "\n",
    "print(cleaned_tweet)\n",
    "cleaned_tweet.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned Tweet\n",
      "0    kadang aku berfikir kenapa aku tetap percaya p...\n",
      "1    aku itu aku ku tau matamu sipit tapi diliat da...\n",
      "2    kaum cebong kapir udah keliatan dongoknya dari...\n",
      "3                                  ya bani taplak dkk \n",
      "4    deklarasi pilkada 2018 aman dan anti hoax warg...\n",
      "..                                                 ...\n",
      "292            haha kalah ni yee org jahat pasti kalah\n",
      "293  gubernurzamannow gusipulputi2 ganjaryasin1 dja...\n",
      "294  yg cinta orba pasti meng idola kan prabowo amp...\n",
      "295  nantang buka dadalah eh nyebut setanlah emang ...\n",
      "296  belah duren yaaaa gak dungu ya gak cebong maaf...\n",
      "\n",
      "[297 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicateexclamation(text):\n",
    "    text = re.sub(r'[!]{2,}', '!', text)\n",
    "    text = re.sub(r'[?]{2,}', '?', text)\n",
    "    return text\n",
    "\n",
    "cleaned_tweet = []\n",
    "for text in first_column_pre_process:\n",
    "    text = lowercase(text)\n",
    "    text = remove_unnecessary_char(text)\n",
    "    text = remove_nonaplhanumeric(text)\n",
    "    text = remove_duplicateexclamation(text)\n",
    "    cleaned_tweet.append(text)\n",
    "\n",
    "cleaned_tweet = pd.DataFrame(cleaned_tweet, columns = ['Cleaned Tweet'])   \n",
    "\n",
    "print(cleaned_tweet)\n",
    "cleaned_tweet.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Cleaned Tweet\n",
      "0    kadang aku berfikir kenapa aku tetap percaya p...\n",
      "1    aku itu aku ku tau matamu sipit tapi diliat da...\n",
      "2    kaum cebong kapir udah keliatan dongoknya dari...\n",
      "3                                  ya bani taplak dkk \n",
      "4    deklarasi pilkada 2018 aman dan anti hoax warg...\n",
      "..                                                 ...\n",
      "292            haha kalah ni yee org jahat pasti kalah\n",
      "293  gubernurzamannow gusipulputi2 ganjaryasin1 dja...\n",
      "294  yg cinta orba pasti meng idola kan prabowo amp...\n",
      "295  nantang buka dadalah eh nyebut setanlah emang ...\n",
      "296  belah duren yaaaa gak dungu ya gak cebong maaf...\n",
      "\n",
      "[297 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "kamus_alay = pd.read_csv('kamusalay.csv')\n",
    "\n",
    "\n",
    "alay_dict_map = dict(zip(kamus_alay['alay'], kamus_alay['arti'])) #zip menyatukan value dengan index yang sama\n",
    "#alay_dict_items = alay_dict_map.items()\n",
    "def normalize_alay(text):\n",
    "    for word in alay_dict_map:\n",
    "        normalized_word = ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "        return normalized_word\n",
    "\n",
    "\n",
    "\n",
    "cleaned_tweet = []\n",
    "for text in first_column_pre_process:\n",
    "    text = lowercase(text)\n",
    "    text = remove_unnecessary_char(text)\n",
    "    text = remove_nonaplhanumeric(text)\n",
    "    text = remove_duplicateexclamation(text)\n",
    "    cleaned_tweet.append(text)\n",
    "    text = normalize_alay(text)\n",
    "\n",
    "cleaned_tweet = pd.DataFrame(cleaned_tweet, columns = ['Cleaned Tweet'])   \n",
    "\n",
    "print(cleaned_tweet)\n",
    "cleaned_tweet.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ChallengeGold': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e3e45181a9f6fbb41b0879ba96c8c1c03f26a158f6fbfe007bdb870d7eac9b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
